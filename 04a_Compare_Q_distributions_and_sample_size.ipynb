{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, truncnorm, multivariate_normal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pylab\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_trunc_dep(meana,stda,meanb,stdb,covar,n):\n",
    "    ref_matrix=[[stda**2,covar],[covar,stdb**2]]\n",
    "    ref_sample=multivariate_normal.rvs(mean=(meana,meanb),cov=ref_matrix, size=3*n)\n",
    "    ref_sample = ref_sample[ref_sample[:,1] > 0]\n",
    "    return ref_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_q(df2):\n",
    "    for name, group in df2.groupby('article'):\n",
    "        for energy, data in group.groupby('energy'):\n",
    "            if energy ==0:\n",
    "                ab_ref=(data.alpha_fit/data.beta_fit).unique()                \n",
    "                a_ref=data.alpha_fit.unique()\n",
    "                a_ref_err=data.alpha_fit_err.unique()\n",
    "                b_ref=data.beta_fit.unique()\n",
    "                b_ref_err=data.beta_fit_err.unique()\n",
    "                covar_ref= data.covar_fit.unique()\n",
    "                \n",
    "            df2.loc[(name,energy),'a_fit_ref'] = a_ref\n",
    "            df2.loc[(name,energy),'a_fit_ref_err'] = a_ref_err\n",
    "            df2.loc[(name,energy),'b_fit_ref'] = b_ref\n",
    "            df2.loc[(name,energy),'b_fit_ref_err'] = b_ref_err\n",
    "            df2.loc[(name,energy),'covar_ref'] = covar_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_q(df2,num):\n",
    "    d={}\n",
    "    for name, group in df2.groupby('article'):\n",
    "        d[name]={}\n",
    "        for energy, data in group.groupby('energy'):\n",
    "\n",
    "            if energy == 0:\n",
    "                d[name][0] = {}\n",
    "                ref_sample = np.array(dist_trunc_dep(data.a_fit_ref.values.max(),\n",
    "                                                     data.a_fit_ref_err.values.max(),\n",
    "                                                     data.b_fit_ref.values.max(),\n",
    "                                                     data.b_fit_ref_err.values,\n",
    "                                                     data.covar_fit,num))\n",
    "                d[name][0][ 'ref_alpha_dep']=ref_sample[:,0]\n",
    "                d[name][0][ 'ref_beta_dep']=ref_sample[:,1]\n",
    "\n",
    "            else:\n",
    "                d[name][energy]={}\n",
    "                ref_sample = np.array(dist_trunc_dep(data.alpha_fit.values.max(),\n",
    "                                                     data.alpha_fit_err.values.max(),\n",
    "                                                     data.beta_fit.values.max(),\n",
    "                                                     data.beta_fit_err.values,data.covar_fit,num))\n",
    "                d[name][energy][ 'alpha_dep']=ref_sample[:,0]\n",
    "                d[name][energy][ 'beta_dep']=ref_sample[:,1]\n",
    "                d[name][energy]['LET']=data.LET.values.max()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac{\\alpha}{\\alpha_{phot}} = 1+ \\frac{q L}{(\\frac{\\alpha}{\\beta})_{phot}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_q_sk(d,i):\n",
    "    x=list()\n",
    "    y=list()\n",
    "    \n",
    "    for k,v in d.items():\n",
    "        for m,n in v.items():\n",
    "            if m>0:\n",
    "                y.append(d[k][m]['alpha_dep'][i] /  d[k][0]['ref_alpha_dep'][i] -1)\n",
    "                x.append(d[k][m]['LET']*d[k][0]['ref_beta_dep'][i]/d[k][0]['ref_alpha_dep'][i])\n",
    "             \n",
    "    x= np.asarray(x).reshape(-1,1)\n",
    "    reg = LinearRegression(fit_intercept=False).fit(x, y)\n",
    "    q=reg.coef_[0]\n",
    "    if q<-1 :\n",
    "        print(k,m,i)\n",
    "    R=reg.score(x,y)\n",
    "    return q,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_file(data_dict,name):\n",
    "    a_file = open(name, \"wb\")\n",
    "    pickle.dump(data_dict, a_file)\n",
    "    a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'legend.fontsize': '20',\n",
    "         'xtick.direction' : 'in',  \n",
    "         'ytick.direction' : 'in', \n",
    "         'xtick.top' : True, \n",
    "         'figure.figsize': (10,6),\n",
    "         'axes.labelsize': '26',\n",
    "         'axes.titlesize':'26',\n",
    "         'xtick.labelsize':'20',\n",
    "         'ytick.labelsize':'20',\n",
    "         'xtick.major.pad':'16',\n",
    "         'ytick.major.pad':'16'}\n",
    "    \n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_fname = os.path.join('tmp','fitted_data.h5')\n",
    "save_fname = os.path.join('tmp','distrib_q.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size =50000\n",
    "\n",
    "df = pd.read_hdf(open_fname,\"data_1\")\n",
    "df = df.groupby([\"article\",'energy']).max()\n",
    "\n",
    "var_q(df)\n",
    "d = dict_q(df,size)\n",
    "\n",
    "qtmp,Rtmp=zip(*[find_q_sk(d,i) for i in range(size)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q= pd.DataFrame(qtmp)\n",
    "q.to_csv('tmp/best_q.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample size-comparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size=[100,200,500,1000,2000,5000,10000,20000]#,50000,100000,200000,500000]\n",
    "index = ['mean','std','median','quantile025','quantile975','R2','time[s]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_compare=pd.DataFrame(columns = sample_size, index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(open_fname,\"data_1\")\n",
    "df = df.groupby([\"article\",'energy']).max()\n",
    "\n",
    "for size in sample_size:\n",
    "    start = time.time()\n",
    "    var_q(df)\n",
    "#create dict\n",
    "    d = dict_q(df,size);\n",
    "\n",
    "#calculate q values and R^2\n",
    "    qtmp,Rtmp=zip(*[find_q_sk(d,i) for i in range(size)])  ;\n",
    "    \n",
    "    R=pd.DataFrame(np.asarray(Rtmp),columns = ['r']);\n",
    "    qdf=pd.DataFrame(np.asarray(qtmp),columns = ['q']);\n",
    "    end = time.time()\n",
    "\n",
    "#compare calculation time for different sample-size    \n",
    "    sample_compare[size] = qdf.q.mean(),qdf.q.std(),qdf.q.median(),qdf.q.quantile(0.025),qdf.q.quantile(0.975),R.r.mean(),(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_compare.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_compare.T.to_excel(\"results/compare_samples_size.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-comparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas= [\"data_1\",\"data_2\",\"data_3\",\"data_4\",\"data_5\",\"data_6\",\"data_7\"]\n",
    "index2 = ['mean','std','median','r2','quantile025','quantile975',\"conditions\",\"exp no\"]\n",
    "\n",
    "conditions = [\"-\",\"AB\",\"ABEFG\",\"ABCD\",\"ABC\",\"ABE\",\"ABG\"]\n",
    "exp_no=[24,24,10,4,20,13,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_compare=pd.DataFrame(columns = datas, index = index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose optimal sample size \n",
    "num=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_q,condition,exp in zip(datas,conditions,exp_no):\n",
    "    df2 = pd.read_hdf(open_fname,data_q)\n",
    "    df2 = df2.groupby([\"article\",'energy']).max()\n",
    "    var_q(df2)\n",
    "#create dict\n",
    "    d = dict_q(df2,num)\n",
    "\n",
    "#calculate q values and R^2\n",
    "    qtmp,Rtmp=zip(*[find_q_sk(d,i) for i in range(num)])\n",
    "    \n",
    "    R=pd.DataFrame(np.asarray(Rtmp),columns = ['r'])\n",
    "    qdf=pd.DataFrame(np.asarray(qtmp),columns = ['q'])\n",
    "    \n",
    "#q distribution parameters: mean, standard deviation, median, r^2   \n",
    "    q_compare[data_q] = qdf.q.mean(),qdf.q.std(),qdf.q.median(),R.r.mean(),qdf.q.quantile(0.025),qdf.q.quantile(0.975),condition,exp\n",
    "#save q distributions\n",
    "    qdf.to_hdf(save_fname, data_q, format='table')\n",
    "    \n",
    "    if data_q == 'data_1':\n",
    "        save_dict_to_file(d,'tmp/sample1_dict_alpha_beta.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_compare.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_compare.T.to_excel(\"results/compare_q_distributions.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
