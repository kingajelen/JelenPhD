{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, truncnorm, multivariate_normal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import corner\n",
    "import pylab\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_gauss(mean, std):\n",
    "    rndnum = 0\n",
    "    while rndnum <= 0:\n",
    "        rndnum = random.gauss(mean, std)\n",
    "    return rndnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_trunc(mean,std,n):\n",
    "    x_dist = truncnorm(a=-mean/std, b=np.inf,loc=mean,scale=std)\n",
    "    return (x_dist.rvs(n)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_trunc_dep(meana,stda,meanb,stdb,covar,n):\n",
    "    ref_matrix=np.array([[stda**2,covar],[covar,stdb**2]])\n",
    "    ref_sample=multivariate_normal.rvs(mean=(meana,meanb),cov=ref_matrix, size=3*n)\n",
    "    ref_sample = ref_sample[ref_sample[:,1] > 0]\n",
    "    return ref_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_q_sk(d,i):\n",
    "    x=list()\n",
    "    y=list()\n",
    "    \n",
    "    for k,v in d.items():\n",
    "        for m,n in v.items():\n",
    "            if m>0:\n",
    "                y.append(d[k][m]['alpha'][i] /  d[k][0]['ref_alpha_dep'][i] -1)\n",
    "                x.append(d[k][m]['LET']*d[k][0]['ref_beta_dep'][i]/d[k][0]['ref_alpha_dep'][i])\n",
    "             \n",
    "    x= np.asarray(x).reshape(-1,1)\n",
    "    reg = LinearRegression(fit_intercept=False).fit(x, y)\n",
    "    q=reg.coef_[0]\n",
    "    if q<-1 :\n",
    "        print(k,m,i)\n",
    "    R=reg.score(x,y)\n",
    "    return q,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_param = {'legend.fontsize': '20',\n",
    "         'xtick.direction' : 'in',  \n",
    "         'ytick.direction' : 'in', \n",
    "         'xtick.top' : True, \n",
    "         'figure.figsize': (10,6),\n",
    "         'axes.labelsize': '26',\n",
    "         'axes.titlesize':'26',\n",
    "         'xtick.labelsize':'20',\n",
    "         'ytick.labelsize':'20',\n",
    "         'xtick.major.pad':'16',\n",
    "         'ytick.major.pad':'16'}\n",
    "    \n",
    "pylab.rcParams.update(style_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_fname = os.path.join('tmp','fitted_data.h5')\n",
    "df = pd.read_hdf(open_fname, 'data_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {\"a(fit)/b(fit)\": \"alpha(fit)/beta(fit)\", \"alfa_fit\":\"alpha_fit\",\"alfa_fit_err\":\"alpha_fit_err\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby([\"article\",'energy']).max()\n",
    "df2.is_copy=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac{\\alpha}{\\alpha_{phot}} = 1+ \\frac{q L}{(\\frac{\\alpha}{\\beta})_{phot}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df2.groupby('article'):\n",
    "        for energy, data in group.groupby('energy'):\n",
    "            if energy ==0:\n",
    "                ab_ref=data[\"alpha(fit)/beta(fit)\"].unique()                \n",
    "                a_ref=data[\"alpha_fit\"].unique()\n",
    "                a_ref_err=data[\"alpha_fit_err\"].unique()\n",
    "                b_ref=data[\"beta_fit\"].unique()\n",
    "                b_ref_err=data[\"beta_fit_err\"].unique()\n",
    "                covar_ref= data[\"covar_fit\"].unique()\n",
    "                \n",
    "                df2.loc[(name,energy),'a_fit_ref'] = a_ref\n",
    "                df2.loc[(name,energy),'a_fit_ref_err'] = a_ref_err\n",
    "                df2.loc[(name,energy),'b_fit_ref'] = b_ref\n",
    "                df2.loc[(name,energy),'b_fit_ref_err'] = b_ref_err\n",
    "                df2.loc[(name,energy),'covar_ref'] = covar_ref\n",
    "            \n",
    "            else:\n",
    "                a=data[\"alpha_fit\"].unique()\n",
    "                a_err=data[\"alpha_fit_err\"].unique()\n",
    "                \n",
    "                aa_ref=data['a(fit)/a_ref(fit)'].unique()\n",
    "                aa_ref_art=data['a/a_ref'].unique()\n",
    "                L=(data[\"LET\"]).unique()\n",
    "                \n",
    "               \n",
    "                q = (aa_ref-1.0)*ab_ref/L\n",
    "                k=(aa_ref-1.0)/L\n",
    "\n",
    "                \n",
    "                error=  np.sqrt(np.power((1-a_ref)/b_ref*a_err,2)+\n",
    "                                np.power((a-1)/b_ref*a_ref_err,2)+\n",
    "                                np.power((a_ref-a)/np.power(b_ref,2)*b_ref_err,2))\n",
    "\n",
    "                df2.loc[(name,energy),'q'] = q\n",
    "                df2.loc[(name,energy),'k'] = k\n",
    "                df2.loc[(name,energy), \"error\"] = error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df2.groupby('article'):\n",
    "        for energy, data in group.groupby('energy'):\n",
    "            df2.loc[(name, energy),\"ab_ref\"]=df2.loc[(name,0), \"alpha(fit)/beta(fit)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "df2.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw alpha & beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df2.groupby('article'):\n",
    "    d[name]={}\n",
    "    for energy, data in group.groupby('energy'):\n",
    "      \n",
    "        if energy == 0:\n",
    "            d[name][0] = {}\n",
    "            d[name][0][ 'ref_alpha'] = dist_trunc(data.a_fit_ref.values, \n",
    "                                                  data.a_fit_ref_err.values, num)\n",
    "            d[name][0][ 'ref_beta'] = dist_trunc(data.b_fit_ref.values, \n",
    "                                                 data.b_fit_ref_err.values, num)\n",
    "            ref_sample = np.array(dist_trunc_dep(data.a_fit_ref.values.max(),\n",
    "                                                 data.a_fit_ref_err.values.max(),\n",
    "                                                 data.b_fit_ref.values.max(),\n",
    "                                                 data.b_fit_ref_err.values,\n",
    "                                                 data.covar_fit,num))\n",
    "            d[name][0][ 'ref_alpha_dep']=ref_sample[:,0]\n",
    "            d[name][0][ 'ref_beta_dep']=ref_sample[:,1]\n",
    "\n",
    "        else:\n",
    "            d[name][energy]={}\n",
    "            d[name][energy][ 'alpha'] = dist_trunc(data.alpha_fit.values, \n",
    "                                                   data.alpha_fit_err.values, num)\n",
    "            d[name][energy][ 'beta'] = dist_trunc(data.beta_fit.values, \n",
    "                                                  data.beta_fit_err.values, \n",
    "                                                  num)\n",
    "            ref_sample = np.array(dist_trunc_dep(data.alpha_fit.values.max(),\n",
    "                                                 data.alpha_fit_err.values.max(),\n",
    "                                                 data.beta_fit.values.max(),\n",
    "                                                 data.beta_fit_err.values,data.covar_fit,num))\n",
    "            d[name][energy][ 'alpha_dep']=ref_sample[:,0]\n",
    "            d[name][energy][ 'beta_dep']=ref_sample[:,1]\n",
    "            d[name][energy]['LET']=data.LET.values.max()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha & Beta distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = d['10'][5010]['alpha_dep']\n",
    "b=(d['10'][5010]['beta_dep'])\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(10,10))\n",
    "\n",
    "# plot 1D histograms\n",
    "ax[0][0].hist(a, bins=100, density=True,color='gray')\n",
    "ax[0][0].set_xlim(0.2,0.4)\n",
    "\n",
    "ax[1][1].hist(b, bins=100, density=True, orientation='horizontal',color='gray')\n",
    "ax[1][1].set_ylim(0.,0.05)\n",
    "\n",
    "\n",
    "ax[0][0].set_title(r'$\\alpha\\; [Gy^{-1}]$'+'\\n')\n",
    "ax[0][0].xaxis.set_ticks_position('top')\n",
    "ax[0][0].set_ylabel('Rozkład gęstości\\n prawdopodobieństwa [-]\\n')\n",
    "\n",
    "ax[1][1].set_ylabel('\\n'+r'$\\beta\\; [Gy^{-2}]$')\n",
    "ax[1][1].set_xlabel('\\nRozkład gęstości\\n prawdopodobieństwa [-]')\n",
    "ax[1][1].yaxis.set_label_coords(1.2, 0.5)\n",
    "\n",
    "ax[1][1].yaxis.tick_right()\n",
    "ax[1][1].yaxis.set_label_position(\"right\")\n",
    "\n",
    "# plot 2D histogram\n",
    "corner.hist2d(x=a, y=b, bins=50, ax=ax[1][0])\n",
    "ax[1][0].set_xlabel('\\n'+r'$\\alpha \\;[Gy^{-1}]$')\n",
    "ax[1][0].set_ylabel(r'$\\beta \\;[Gy^{-2}]$'+'\\n')\n",
    "\n",
    "ax[1][0].set_xlim(0.2,0.4)\n",
    "ax[1][0].set_ylim(0.,0.05)\n",
    "\n",
    "\n",
    "# common settings\n",
    "for axx in ax.flatten():\n",
    "    axx.grid()\n",
    "    axx.minorticks_on()\n",
    "    axx.grid(which='major', linestyle=':', linewidth='0.2', color='k')\n",
    "    axx.grid(which='minor', linestyle=':', linewidth='0.2', color='k')\n",
    "\n",
    "ax[0][1].set_visible(False)\n",
    "\n",
    "ax[1][0].legend( ['korelacja -0.936'],\n",
    "          loc='upper right', frameon=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=pd.DataFrame(list(zip(a,b)),\n",
    "                          columns=['alpha','beta'])\n",
    "tmp.to_csv(\"results/figure_5_2\")\n",
    "fig.savefig(fname=\"results/figure_5_2\",dpi= 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=list()\n",
    "y=list()\n",
    "i=0  \n",
    "\n",
    "fig,ax = plt.subplots(figsize = (10,6))\n",
    "\n",
    "for k,v in d.items():\n",
    "\n",
    "    for m,n in v.items():\n",
    "        if m>0:\n",
    "            #print(i,k,m)\n",
    "            y.append(d[k][m]['alpha'][i] /  d[k][0]['ref_alpha_dep'][i]-1)\n",
    "            x.append(d[k][m]['LET']*d[k][0]['ref_beta_dep'][i]/d[k][0]['ref_alpha_dep'][i])\n",
    "    \n",
    "ax.plot(x,y, \".\",c='black',markersize=15)\n",
    "\n",
    "ax.set_xlabel('\\n'+r'$LET \\cdot \\beta_{ref}\\cdot \\alpha^{-1}_{ref} \\;[Gy\\cdot  keV  \\cdot\\mu m^{-1}]$')\n",
    "ax.set_ylabel(r'$(\\alpha \\cdot \\alpha^{-1}_{ref})-1 \\;[-]$'+'\\n')\n",
    "\n",
    "ax.grid()\n",
    "ax.minorticks_on()\n",
    "ax.grid(which='minor', linestyle=':', linewidth='0.2', color='k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=pd.DataFrame(list(zip(x,y)),\n",
    "                          columns=['data_x','data_y'])\n",
    "tmp.to_csv(\"results/figure_5_4\")\n",
    "\n",
    "fig.savefig(fname=\"results/figure_5_4\",dpi= 700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qtmp,Rtmp=zip(*[find_q_sk(d,i) for i in range(num)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=pd.DataFrame(np.asarray(Rtmp))\n",
    "qdf=pd.DataFrame(np.asarray(qtmp))\n",
    "qdf.columns = ['q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf.q.mean(), qdf.q.std(), qdf.q.median(), qdf.q.quantile(0.025),qdf.q.quantile(0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (10,6))\n",
    "\n",
    "qdf.q.hist(bins=(200), density=True,color='grey')\n",
    "ax.axvline(x=0.434, label='q = 0.434'.format(0.434),c='k',ls='--',lw=2.2)\n",
    "\n",
    "ax.set_xlim(0,0.6)\n",
    "ax.set_xlabel('\\n'+r'$q\\; [Gy\\cdot \\mu m \\cdot keV^{-1}]$')\n",
    "ax.set_ylabel(\"Rozkład gęstości \\nprawdopodobieństwa [-]\\n\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.minorticks_on()\n",
    "ax.grid(which='minor', linestyle=':', linewidth='0.2', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=pd.DataFrame(list(zip(qdf.q)),\n",
    "                          columns=['q'])\n",
    "tmp.to_csv(\"results/figure_5_7\")\n",
    "fig.savefig(fname=\"results/figure_5_7\",dpi= 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
